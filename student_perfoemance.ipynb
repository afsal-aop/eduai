{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"studytime\", \"absences\", \"G1\", \"G2\", \"failures\", \"goout\", \"health\"]\n",
    "X = df[features]\n",
    "y = df[\"G3\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train (Fit) the model using training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict student grades on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Model Training Complete! ðŸŽ‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Calculate MAE (lower is better)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate RÂ² score (closer to 1 is better)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"RÂ² Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RÂ² = 0.80? â†’ The model is 80% accurate in predicting student grades\n",
    "MAE = 1.5? â†’ On average, the model is 1.5 points off when predicting grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict student grades\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Check accuracy\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest MAE: {mae_rf}\")\n",
    "print(f\"Random Forest RÂ² Score: {r2_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Random Forest uses many decision trees ðŸŒ²ðŸŒ²ðŸŒ² to improve predictions.\n",
    "It reduces errors and improves accuracy compared to Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new student data point (in the same format as training data)\n",
    "new_student = pd.DataFrame({\n",
    "    \"studytime\": [3],\n",
    "    \"absences\": [5],\n",
    "    \"G1\": [14],\n",
    "    \"G2\": [15],\n",
    "    \"failures\": [0],\n",
    "    \"goout\": [2],\n",
    "    \"health\": [4]\n",
    "})\n",
    "\n",
    "# Predict Final Grade\n",
    "predicted_grade = rf_model.predict(new_student)\n",
    "print(f\"Predicted Final Grade (G3): {predicted_grade[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scatter plot of predicted vs actual grades\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=y_test, y=y_pred_rf)\n",
    "plt.xlabel(\"Actual Grades (G3)\")\n",
    "plt.ylabel(\"Predicted Grades (G3)\")\n",
    "plt.title(\"Actual vs Predicted Student Grades\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If points fall near the diagonal line, predictions are accurate.\n",
    "If points are far from the line, the model made mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance scores from Random Forest model\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=importances, y=feature_names)\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance for Predicting Final Grade\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If G2 and G1 have high importance, it means previous grades strongly affect the final grade.\n",
    "If absences or goout have low importance, they donâ€™t affect grades much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Tested the model on a new student.\n",
    "âœ… Plotted actual vs. predicted grades to see accuracy.\n",
    "âœ… Analyzed feature importance to understand what impacts grades the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Number of trees\n",
    "    \"max_depth\": [5, 10, None],  # Tree depth\n",
    "    \"min_samples_split\": [2, 5, 10]  # Minimum samples per split\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, n_jobs=-1, scoring=\"r2\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model has hyperparameters like:\n",
    "\n",
    "n_estimators â†’ Number of trees ðŸŒ³\n",
    "max_depth â†’ How deep each tree goes ðŸŒ²\n",
    "min_samples_split â†’ Minimum data points needed to split a node ðŸ”ª\n",
    "The model tests different hyperparameters automatically.\n",
    "It finds the best combination for higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best parameters from Grid Search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train a new model with the best settings\n",
    "best_rf_model = RandomForestRegressor(**best_params, random_state=42)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict again\n",
    "y_pred_best = best_rf_model.predict(X_test)\n",
    "\n",
    "# Check new accuracy\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Optimized Model MAE: {mae_best}\")\n",
    "print(f\"Optimized Model RÂ² Score: {r2_best}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model is more accurate because it uses the best settings.\n",
    "The RÂ² Score should improve (closer to 1 means better predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original Model RÂ²: {r2_rf}\")\n",
    "print(f\"Optimized Model RÂ²: {r2_best}\")\n",
    "\n",
    "print(f\"Original Model MAE: {mae_rf}\")\n",
    "print(f\"Optimized Model MAE: {mae_best}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing the changes\n",
    "âœ… Used GridSearchCV to find the best hyperparameters.\n",
    "âœ… Trained a better model with the best settings.\n",
    "âœ… Compared old vs. new model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flask pandas xgboost scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Train a new model (use the best hyperparameters from your tuning)\n",
    "model = XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)  # Make sure X_train and y_train are defined\n",
    "\n",
    "# Save the model in the correct XGBoost format\n",
    "model.save_model(\"student_grade_model.json\")  # Saves in the right format\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
